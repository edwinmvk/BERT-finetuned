{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Anatomy Chatbot with BERT\n",
    "\n",
    "This notebook implements a chatbot for human anatomy using BERT and Flask. Follow the cells in order to:\n",
    "1. Set up the environment\n",
    "2. Load and prepare data\n",
    "3. Train the model\n",
    "4. Launch the API server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    TrainingArguments, \n",
    "    Trainer\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "from flask import Flask, request, jsonify\n",
    "from typing import Dict, Any\n",
    "import time\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnatomyChatbot:\n",
    "    def __init__(self, model_name: str = \"bert-base-uncased\", model_dir: str = \"./final_anatomy_model\"):\n",
    "        self.model_name = model_name\n",
    "        self.model_dir = model_dir\n",
    "        self.initialize_model()\n",
    "        self.qa_pairs = []\n",
    "    \n",
    "    def initialize_model(self):\n",
    "        \"\"\"Initialize or load the model and tokenizer\"\"\"\n",
    "        try:\n",
    "            if os.path.exists(self.model_dir):\n",
    "                print(f\"Loading model from {self.model_dir}\")\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(self.model_dir)\n",
    "                self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                    self.model_dir,\n",
    "                    num_labels=1\n",
    "                )\n",
    "                print(\"Model loaded successfully\")\n",
    "            else:\n",
    "                print(\"No saved model found. Initializing new model...\")\n",
    "                self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "                self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                    self.model_name,\n",
    "                    num_labels=1,\n",
    "                    problem_type=\"regression\"  # Specify regression problem\n",
    "                )\n",
    "                print(\"New model initialized\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error during model initialization: {e}\")\n",
    "            print(\"Falling back to new model initialization...\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                self.model_name,\n",
    "                num_labels=1,\n",
    "                problem_type=\"regression\"  # Specify regression problem\n",
    "            )\n",
    "            \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def tokenize_function(self, examples):\n",
    "        \"\"\"Tokenize the input text and properly format labels\"\"\"\n",
    "        tokenized = self.tokenizer(\n",
    "            examples['text'],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512\n",
    "        )\n",
    "        \n",
    "        # Convert labels to float32 tensor and reshape\n",
    "        tokenized['labels'] = torch.tensor(examples['labels'], dtype=torch.float32).reshape(-1, 1)\n",
    "        return tokenized\n",
    "\n",
    "    def prepare_datasets(self, dataset: pd.DataFrame, train_ratio: float = 0.8):\n",
    "        \"\"\"Prepare and process datasets for training\"\"\"\n",
    "        # Split the dataset\n",
    "        train_size = int(len(dataset) * train_ratio)\n",
    "        train_data = dataset.iloc[:train_size]\n",
    "        test_data = dataset.iloc[train_size:]\n",
    "        \n",
    "        # Convert to HuggingFace datasets\n",
    "        train_dataset = Dataset.from_pandas(train_data)\n",
    "        test_dataset = Dataset.from_pandas(test_data)\n",
    "        \n",
    "        # Map the tokenization function across the datasets\n",
    "        train_dataset = train_dataset.map(\n",
    "            self.tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=train_dataset.column_names\n",
    "        )\n",
    "        \n",
    "        test_dataset = test_dataset.map(\n",
    "            self.tokenize_function,\n",
    "            batched=True,\n",
    "            remove_columns=test_dataset.column_names\n",
    "        )\n",
    "        \n",
    "        print(f\"Training set size: {len(train_dataset)}\")\n",
    "        print(f\"Testing set size: {len(test_dataset)}\")\n",
    "        \n",
    "        return train_dataset, test_dataset\n",
    "    \n",
    "    def load_and_prepare_dataset(self, folder_path: str) -> pd.DataFrame:\n",
    "        \"\"\"Load and prepare dataset from JSONL files\"\"\"\n",
    "        all_data = []\n",
    "        \n",
    "        if not os.path.exists(folder_path):\n",
    "            raise FileNotFoundError(f\"Directory {folder_path} not found\")\n",
    "            \n",
    "        jsonl_files = [f for f in os.listdir(folder_path) if f.endswith('.jsonl')]\n",
    "        if not jsonl_files:\n",
    "            raise FileNotFoundError(f\"No JSONL files found in {folder_path}\")\n",
    "            \n",
    "        for file_name in jsonl_files:\n",
    "            with open(os.path.join(folder_path, file_name), 'r', encoding='utf-8') as file:\n",
    "                for line in file:\n",
    "                    data = json.loads(line)\n",
    "                    if 'question' in data and 'answer' in data:\n",
    "                        all_data.append({\n",
    "                            'question': data['question'],\n",
    "                            'answer': data['answer'],\n",
    "                            'text': f\"{data['question']} [SEP] {data['answer']}\"\n",
    "                        })\n",
    "                        self.qa_pairs.append({\n",
    "                            'question': data['question'],\n",
    "                            'answer': data['answer']\n",
    "                        })\n",
    "        \n",
    "        df = pd.DataFrame(all_data)\n",
    "        df['labels'] = np.zeros(len(df))\n",
    "        return df[['text', 'labels']]\n",
    "    \n",
    "    def split_dataset(self, df: pd.DataFrame, train_ratio: float = 0.8) -> tuple:\n",
    "        \"\"\"Split dataset into training and testing sets\"\"\"\n",
    "        train_size = int(len(df) * train_ratio)\n",
    "        train_data = df.iloc[:train_size]\n",
    "        test_data = df.iloc[train_size:]\n",
    "        return train_data, test_data\n",
    "    \n",
    "    \n",
    "    def train_and_evaluate(self, train_dataset, test_dataset, force_train: bool = False) -> Dict[str, Any]:\n",
    "        \"\"\"Train if necessary and evaluate the model\"\"\"\n",
    "        # Initialize model and tokenizer\n",
    "        self.initialize_model()\n",
    "        \n",
    "        if force_train or not os.path.exists(self.model_dir):\n",
    "            print(\"Starting model training...\")\n",
    "            training_args = TrainingArguments(\n",
    "                output_dir=\"./training_outputs\",\n",
    "                eval_strategy=\"epoch\",\n",
    "                save_strategy=\"epoch\",\n",
    "                learning_rate=2e-5,\n",
    "                per_device_train_batch_size=8,\n",
    "                per_device_eval_batch_size=8,\n",
    "                num_train_epochs=3,\n",
    "                weight_decay=0.01,\n",
    "                logging_dir=\"./training_logs\",\n",
    "                logging_steps=10,\n",
    "                load_best_model_at_end=True,\n",
    "                metric_for_best_model=\"loss\",\n",
    "                greater_is_better=False\n",
    "            )\n",
    "            \n",
    "            # Define compute_metrics function: compute_metrics function that calculates Mean Squared Error (MSE) between predictions and labels\n",
    "            def compute_metrics(eval_pred):\n",
    "                logits, labels = eval_pred\n",
    "                predictions = torch.sigmoid(torch.tensor(logits)).numpy()\n",
    "                return {\n",
    "                    \"mse\": ((predictions - labels) ** 2).mean().item()\n",
    "                }\n",
    "            \n",
    "            # Configure Trainer with compute_metrics\n",
    "            trainer = Trainer(\n",
    "                model=self.model,\n",
    "                args=training_args,\n",
    "                train_dataset=train_dataset,\n",
    "                eval_dataset=test_dataset,\n",
    "                compute_metrics=compute_metrics\n",
    "            )\n",
    "            \n",
    "            # Train the model\n",
    "            trainer.train()\n",
    "            \n",
    "            # Save the final model\n",
    "            print(f\"Saving model to {self.model_dir}\")\n",
    "            if os.path.exists(self.model_dir):\n",
    "                shutil.rmtree(self.model_dir)\n",
    "            trainer.save_model(self.model_dir)\n",
    "            self.tokenizer.save_pretrained(self.model_dir)\n",
    "\n",
    "            # Clean up temporary directories\n",
    "            if os.path.exists(\"./training_outputs\"):\n",
    "                shutil.rmtree(\"./training_outputs\")\n",
    "            if os.path.exists(\"./training_logs\"):\n",
    "                shutil.rmtree(\"./training_logs\")\n",
    "        \n",
    "        try:\n",
    "            print(\"Evaluating model on test dataset...\")\n",
    "            # Evaluate the model\n",
    "            trainer = Trainer(\n",
    "                model=self.model,\n",
    "                tokenizer=self.tokenizer,\n",
    "                # compute_metrics=compute_metrics,\n",
    "                eval_dataset=test_dataset\n",
    "            )\n",
    "\n",
    "            # Clean up temporary directories like tmp_trainer created by huggingface\n",
    "            if os.path.exists(\"./tmp_trainer\"):\n",
    "                shutil.rmtree(\"./tmp_trainer\")\n",
    "\n",
    "            # Evaluate the model\n",
    "            metrics = trainer.evaluate()\n",
    "            \n",
    "            # Assuming `trainer` provides predictions and true labels\n",
    "            predictions = trainer.predict(test_dataset).predictions\n",
    "            true_labels = test_dataset['labels']\n",
    "            \n",
    "            # Convert predictions to class indices if necessary\n",
    "            predicted_labels = predictions.argmax(axis=-1)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "            \n",
    "            # Add accuracy to metrics\n",
    "            metrics['accuracy'] = accuracy\n",
    "\n",
    "            return metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error during Evaluation: {e}\")\n",
    "\n",
    "    def predict(self, question: str) -> Dict[str, Any]:\n",
    "        \"\"\"Find the most relevant answer for a given question\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Ensure model is initialized\n",
    "        if self.model is None or self.tokenizer is None:\n",
    "            self.initialize_model()\n",
    "        \n",
    "        # Find the most similar question in our dataset\n",
    "        best_match = None\n",
    "        best_score = -1\n",
    "        \n",
    "        for qa_pair in self.qa_pairs:\n",
    "            inputs = self.tokenizer(\n",
    "                question,\n",
    "                qa_pair['question'],\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            ).to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs)\n",
    "                score = torch.sigmoid(outputs.logits).item()\n",
    "                \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = qa_pair\n",
    "        \n",
    "        if not best_match:\n",
    "            return {\n",
    "                \"answer\": \"I couldn't find a relevant answer to your question.\",\n",
    "                \"confidence\": 0.0,\n",
    "                \"response_time\": time.time() - start_time\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"question\": best_match['question'],\n",
    "            \"answer\": best_match['answer'],\n",
    "            \"confidence\": best_score,\n",
    "            \"response_time\": time.time() - start_time\n",
    "        }\n",
    "# Initialize the chatbot\n",
    "chatbot = AnatomyChatbot(model_dir=\"./final_anatomy_model\")\n",
    "print(\"Chatbot initialized successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the dataset\n",
    "# Update this path to where your JSONL files are stored\n",
    "DATA_DIR = \"./data\"\n",
    "\n",
    "try:\n",
    "    # Load dataset\n",
    "    dataset = chatbot.load_and_prepare_dataset(DATA_DIR)\n",
    "    print(f\"Dataset loaded successfully. Shape: {dataset.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "\n",
    "try:\n",
    "    # Prepare the datasets (this handles splitting, conversion, and tokenization)\n",
    "    train_dataset, test_dataset = chatbot.prepare_datasets(dataset)\n",
    "    print(\"Dataset prepared\")\n",
    "except Exception as e:\n",
    "    print(f\"Dataset preparation error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "try:\n",
    "    print(\"Starting model training...\")\n",
    "    metrics = chatbot.train_and_evaluate(train_dataset, test_dataset)\n",
    "    print(\"\\nTraining completed. Final metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy testing\n",
    "result = chatbot.predict('What is anatomy?')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask API setup\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_endpoint():\n",
    "    try:\n",
    "        data = request.json\n",
    "        if not data or 'input' not in data:\n",
    "            return jsonify({\"error\": \"No input provided\"}), 400\n",
    "            \n",
    "        result = chatbot.predict(data['input'])\n",
    "        return jsonify(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 500\n",
    "\n",
    "# Start the Flask server\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(host=\"0.0.0.0\", port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the API\n",
    "\n",
    "Once the Flask server is running, you can test it using the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Test the API\n",
    "test_text = \"The human heart has four chambers\"\n",
    "response = requests.post('http://localhost:5000/predict', json={'input': test_text})\n",
    "\n",
    "print(\"API Response:\")\n",
    "print(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
